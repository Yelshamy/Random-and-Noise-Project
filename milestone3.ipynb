{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19891fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "Accuracy: 0.90\n",
      "Precision: 0.91\n",
      "Recall: 0.88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "data = pd.read_csv('Train_Data.csv')\n",
    "\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Identify columns\n",
    "categorical_columns = data.select_dtypes(include=\"object\").drop(columns=[\"class\"]).columns\n",
    "numerical_columns = data.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Ensure class labels are consistent\n",
    "data[\"class\"] = data[\"class\"].map({\"normal\": 0, \"anomaly\": 1})\n",
    "\n",
    "# Calculate priors (class probabilities)\n",
    "priors = data[\"class\"].value_counts(normalize=True).to_dict()\n",
    "\n",
    "# Calculate probabilities for categorical features\n",
    "categorical_probs = {}\n",
    "for col in categorical_columns:\n",
    "    categorical_probs[col] = data.groupby(\"class\")[col].value_counts(normalize=True).unstack(fill_value=0)\n",
    "\n",
    "# Numerical Feature Probabilities\n",
    "numerical_dists = {col: {} for col in numerical_columns}\n",
    "for col in numerical_columns:\n",
    "    for cls in data[\"class\"].unique():\n",
    "        cls_data = data[data[\"class\"] == cls][col]\n",
    "        mean = cls_data.mean()\n",
    "        std = cls_data.std()\n",
    "        \n",
    "        # Handle zero standard deviation\n",
    "        if std == 0 or np.isnan(std):\n",
    "            std = 1e-6  # Small positive value to avoid division by zero\n",
    "        \n",
    "        numerical_dists[col][cls] = (mean, std)\n",
    "\n",
    "X_categorical = data[categorical_columns]\n",
    "X_numerical = data[numerical_columns]\n",
    "\n",
    "# NaÃ¯ve Bayes Prediction Function\n",
    "def naive_bayes_predict(row):\n",
    "    posteriors = {}\n",
    "    for cls in data[\"class\"].unique():\n",
    "        posterior = priors[cls]  # Start with the prior\n",
    "        \n",
    "        # Categorical features\n",
    "        for col in categorical_columns:\n",
    "            if row[col] in categorical_probs[col].columns:\n",
    "                posterior *= categorical_probs[col].loc[cls, row[col]]\n",
    "            else:\n",
    "                posterior *= 0  # Handle unseen categories\n",
    "        \n",
    "        # Numerical features\n",
    "        for col in numerical_columns:\n",
    "            mean, std = numerical_dists[col][cls]\n",
    "            try:\n",
    "                posterior *= norm.pdf(row[col], loc=mean, scale=std)\n",
    "            except RuntimeWarning:\n",
    "                posterior *= 1e-9  # Assign a very small probability in case of errors\n",
    "        \n",
    "        posteriors[cls] = posterior\n",
    "    \n",
    "    # Return class with highest posterior probability\n",
    "    return max(posteriors, key=posteriors.get)\n",
    "\n",
    "\n",
    "\n",
    "# Apply prediction to the entire dataset\n",
    "data[\"predicted_class\"] = data.apply(naive_bayes_predict, axis=1)\n",
    "\n",
    "#print(\"Categorical Columns:\", categorical_columns)\n",
    "#print(\"Numerical Columns:\", numerical_columns)\n",
    "\n",
    "# Map class labels back to original\n",
    "data[\"class\"] = data[\"class\"].map({0: \"normal\", 1: \"anomaly\"})\n",
    "data[\"predicted_class\"] = data[\"predicted_class\"].map({0: \"normal\", 1: \"anomaly\"})\n",
    "\n",
    "# Compare with actual labels and calculate accuracy\n",
    "accuracy = (data[\"predicted_class\"] == data[\"class\"]).mean()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "#Calculate confusion matrix components\n",
    "TP = ((data[\"class\"] == \"anomaly\") & (data[\"predicted_class\"] == \"anomaly\")).sum()  # True Positives\n",
    "TN = ((data[\"class\"] == \"normal\") & (data[\"predicted_class\"] == \"normal\")).sum()  # True Negatives\n",
    "FP = ((data[\"class\"] == \"normal\") & (data[\"predicted_class\"] == \"anomaly\")).sum()  # False Positives\n",
    "FN = ((data[\"class\"] == \"anomaly\") & (data[\"predicted_class\"] == \"normal\")).sum()  # False Negatives\n",
    "\n",
    "# Calculate Accuracy, Precision, and Recall\n",
    "#accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0  # Avoid division by zero\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # Avoid division by zero\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Display predictions for reference\n",
    "#print(data[[\"class\", \"predicted_class\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab64747",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.56\n",
      "Precision: 0.80\n",
      "Recall: 0.08\n",
      "----------------------------------------\n",
      "Model: Multinomial Naive Bayes\n",
      "Accuracy: 0.55\n",
      "Precision: 0.64\n",
      "Recall: 0.10\n",
      "----------------------------------------\n",
      "Model: Bernoulli Naive Bayes\n",
      "Accuracy: 0.90\n",
      "Precision: 0.95\n",
      "Recall: 0.84\n",
      "----------------------------------------\n",
      "\n",
      "Model Comparison:\n",
      "                     Model  Accuracy  Precision    Recall\n",
      "0     Gaussian Naive Bayes  0.557253   0.799107  0.075687\n",
      "1  Multinomial Naive Bayes  0.551498   0.638522  0.102326\n",
      "2    Bernoulli Naive Bayes  0.902957   0.945394  0.841860\n",
      "\n",
      "Best Model Based on Accuracy: Bernoulli Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('Train_Data.csv')\n",
    "\n",
    "# Clean data (replace NaN and inf values)\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Identify categorical columns and separate the target column ('class')\n",
    "categorical_columns = data.select_dtypes(include=\"object\").drop(columns=[\"class\"]).columns\n",
    "numerical_columns = data.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Ensure class labels are consistent (map 'normal' to 0, 'anomaly' to 1)\n",
    "data[\"class\"] = data[\"class\"].map({\"normal\": 0, \"anomaly\": 1})\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data_encoded.drop(columns=[\"class\"])  # Drop the target column from features\n",
    "y = data_encoded[\"class\"]  # Target column\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models to train\n",
    "models = {\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    \"Bernoulli Naive Bayes\": BernoulliNB()\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": []\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Append metrics to the dictionary\n",
    "    metrics[\"Model\"].append(model_name)\n",
    "    metrics[\"Accuracy\"].append(accuracy)\n",
    "    metrics[\"Precision\"].append(precision)\n",
    "    metrics[\"Recall\"].append(recall)\n",
    "\n",
    "    # Print results for the current model\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# You can compare these results to determine which model performs best based on your needs.\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Find the best model based on a chosen metric (e.g., accuracy)\n",
    "best_model_index = metrics_df[\"Accuracy\"].idxmax()\n",
    "best_model_name = metrics_df.loc[best_model_index, \"Model\"]\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(metrics_df)\n",
    "print(f\"\\nBest Model Based on Accuracy: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f49b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
