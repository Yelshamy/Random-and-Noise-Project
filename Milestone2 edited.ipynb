{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87efeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm, expon, uniform, pareto\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eba1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66a78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_copy = pd.read_csv(\"Train_data_original.csv\")\n",
    "data = original_copy\n",
    "\n",
    "#Exluding the class column\n",
    "without_column = df.drop(columns='class')\n",
    "\n",
    "#splitting data\n",
    "train_data, test_data = train_test_split(without_column, test_size=0.3, random_state=42)\n",
    "\n",
    "# Save the splits if needed\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False)\n",
    "\n",
    "print(\"Data is prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_columns = train_data.select_dtypes(include=['number'])\n",
    "z_scores = (n_columns - n_columns.mean()) / n_columns.std()\n",
    "\n",
    "def detect_a(z_scores, threshold=3):\n",
    "\n",
    "    anomalies = (np.abs(z_scores) > threshold).any(axis=1)\n",
    "    return pd.DataFrame({'is_anomaly': anomalies})\n",
    "\n",
    "# Example: Use a threshold of 3\n",
    "threshold = 3\n",
    "anomaly_results = detect_a(z_scores, threshold)\n",
    "\n",
    "# Add 'is_anomaly' to the original training dataset\n",
    "train_data['is_anomaly'] = anomaly_results['is_anomaly']\n",
    "\n",
    "#Testing\n",
    "thresholds = [1.5, 2.5, 3, 4.5]\n",
    "for t in thresholds:\n",
    "    anomalies = detect_a(z_scores, t)\n",
    "    print(f\"Threshold: {t}, Anomalies Detected: {anomalies['is_anomaly'].sum()}\")\n",
    "\n",
    "print(\"Z-score computation and anomaly detection successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Train_data_original.csv\") \n",
    "\n",
    "\n",
    "# True labels and predicted labels\n",
    "y_true = data['class']\n",
    "y_pred = data['is_anomaly']\n",
    "\n",
    "# Calculate confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (tp + tn) / len(data)\n",
    "\n",
    "# Print results\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate precision\n",
    "precision = tp / (tp + fp) if (tp + fp) != 0 else 0  # Prevent division by zero\n",
    "\n",
    "# Print results\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate recall\n",
    "recall = tp / (tp + fn) if (tp + fn) != 0 else 0  # Prevent division by zero\n",
    "\n",
    "# Print results\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a68cd975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best fit: pareto with MSE = 14.5750\n",
      "Processing column: srv_rerror_rate\n",
      "  Best fit: gamma with MSE = 13.0248\n",
      "Processing column: same_srv_rate\n",
      "  Best fit: uniform with MSE = 11.1474\n",
      "Processing column: diff_srv_rate\n",
      "  Best fit: expon with MSE = 1.6225\n",
      "Processing column: srv_diff_host_rate\n",
      "  Best fit: pareto with MSE = 10.1153\n",
      "Processing column: dst_host_count\n",
      "  Best fit: uniform with MSE = 0.0002\n",
      "Processing column: dst_host_srv_count\n",
      "  Best fit: lognorm with MSE = 0.0000\n",
      "Processing column: dst_host_same_srv_rate\n",
      "  Best fit: lognorm with MSE = 4.9607\n",
      "Processing column: dst_host_diff_srv_rate\n",
      "  Best fit: expon with MSE = 1.8331\n",
      "Processing column: dst_host_same_src_port_rate\n",
      "  Best fit: gamma with MSE = 4.9645\n",
      "Processing column: dst_host_srv_diff_host_rate\n",
      "  Best fit: expon with MSE = 2.2972\n",
      "Processing column: dst_host_serror_rate\n",
      "  Best fit: gamma with MSE = 7.3713\n",
      "Processing column: dst_host_srv_serror_rate\n",
      "  Best fit: gamma with MSE = 10.1492\n",
      "Processing column: dst_host_rerror_rate\n",
      "  Best fit: gamma with MSE = 12.5998\n",
      "Processing column: dst_host_srv_rerror_rate\n",
      "  Best fit: gamma with MSE = 13.5235\n",
      "Processing column: class\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for abs(): 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16000\\3201642189.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# Fit PDFs for the column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mfit_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_pdfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mbest_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16000\\3201642189.py\u001b[0m in \u001b[0;36mfit_pdfs\u001b[1;34m(column_data)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Function to fit PDFs and calculate MSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfit_pdfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mrange_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mrange_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Adjusted range for fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for abs(): 'str'"
     ]
    }
   ],
   "source": [
    "original_data = original_copy\n",
    "train_data = original_copy\n",
    "\n",
    "# Bring the 'class' column back from original data\n",
    "train_data['class'] = original_data.loc[train_data.index, 'class']\n",
    "\n",
    "# Convert 'class' column to binary values\n",
    "train_data['class'] = train_data['class'].map({'anomaly': 1, 'normal': 0})\n",
    "\n",
    "# Exclude columns with zero variance\n",
    "numerical_columns = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "numerical_columns = [col for col in numerical_columns if train_data[col].std() > 0]\n",
    "\n",
    "\n",
    "# Replace NaN/Inf values\n",
    "train_data = train_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "\n",
    "distributions = [\n",
    "    stats.uniform, stats.expon, stats.norm, stats.pareto, stats.gamma, stats.lognorm\n",
    "]\n",
    "\n",
    "# Function to fit PDFs and calculate MSE\n",
    "def fit_pdfs(column_data):\n",
    "    range_min = column_data.min() - 0.1 * abs(column_data.min())\n",
    "    range_max = column_data.max() + 0.1 * abs(column_data.max())\n",
    "    x = np.linspace(range_min, range_max, 100)  # Adjusted range for fitting\n",
    "    \n",
    "    results = []\n",
    "    for dist in distributions:\n",
    "        try:\n",
    "            params = dist.fit(column_data)\n",
    "            pdf = dist.pdf(x, *params)\n",
    "            histogram_density, bins = np.histogram(column_data, bins=30, density=True)\n",
    "            bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "            mse = np.mean((histogram_density - np.interp(bin_centers, x, pdf))**2)\n",
    "            results.append((dist.name, mse, params, pdf))\n",
    "        except Exception:\n",
    "            pass  # Skip distributions that fail\n",
    "    return sorted(results, key=lambda x: x[1])  # Sort by MSE\n",
    "\n",
    "# Dictionary to store results for each column\n",
    "results_summary = {}\n",
    "\n",
    "# Loop through all numerical columns\n",
    "for column in numerical_columns:\n",
    "    print(f\"Processing column: {column}\")\n",
    "    column_data = data[column]\n",
    "    \n",
    "    # Fit PDFs for the column\n",
    "    fit_results = fit_pdfs(column_data)\n",
    "    best_fit = fit_results[0]\n",
    "    \n",
    "    # Store the best fit results in the summary dictionary\n",
    "    results_summary[column] = {\n",
    "        \"Best Fit\": best_fit[0],\n",
    "        \"MSE\": best_fit[1],\n",
    "        \"Parameters\": best_fit[2]\n",
    "    }\n",
    "    \n",
    "    print(f\"  Best fit: {best_fit[0]} with MSE = {best_fit[1]:.4f}\")\n",
    "    \n",
    "    # Plot histogram and best-fit PDF\n",
    "    #x = np.linspace(column_data.min(), column_data.max(), 100)\n",
    "    #plt.hist(column_data, bins=30, density=True, alpha=0.5, label=\"Data Histogram\")\n",
    "    #plt.plot(x, best_fit[3], label=f\"Best Fit: {best_fit[0]} (MSE={best_fit[1]:.4f})\", color=\"red\")\n",
    "    #plt.title(f\"Best PDF Fit for {column}\")\n",
    "    #plt.xlabel(\"Value\")\n",
    "    #plt.ylabel(\"Density\")\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "# Print a summary of the best fits\n",
    "print(\"\\nSummary of Best Fits:\")\n",
    "for column, result in results_summary.items():\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"  Best Fit: {result['Best Fit']}\")\n",
    "    print(f\"  MSE: {result['MSE']:.4f}\")\n",
    "    print(f\"  Parameters: {result['Parameters']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92adce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'class' column to binary (0 for normal, 1 for anomaly)\n",
    "train_data['class'] = train_data['class'].map({'normal': 0, 'anomaly': 1})\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = train_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "\n",
    "def calculate_and_display_pmfs(data, class_col=\"class\"):\n",
    "    # Check for the class column\n",
    "    if class_col not in data.columns:\n",
    "        raise ValueError(f\"'{class_col}' column not found in dataset.\")\n",
    "    \n",
    "    # Identify categorical columns (excluding the class column)\n",
    "    categorical_columns = data.select_dtypes(include=\"object\").columns\n",
    "\n",
    "    # Calculate PMFs for each column\n",
    "    for column in categorical_columns:\n",
    "        print(f\"Calculating PMF for column: {column}\")\n",
    "        \n",
    "        # Overall PMF\n",
    "        overall_pmf = data[column].value_counts(normalize=True)\n",
    "        \n",
    "        # Conditional PMFs\n",
    "        anomaly_pmf = data[data[class_col] == 1][column].value_counts(normalize=True)\n",
    "        normal_pmf = data[data[class_col] == 0][column].value_counts(normalize=True)\n",
    "        \n",
    "        # Display PMFs\n",
    "        print(f\"\\nPMF for column: {column}\")\n",
    "        print(\"Overall PMF:\")\n",
    "        print(overall_pmf)\n",
    "        print(\"\\nConditional PMF for Anomalies (class=1):\")\n",
    "        print(anomaly_pmf)\n",
    "        print(\"\\nConditional PMF for Normal (class=0):\")\n",
    "        print(normal_pmf)\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Calculate and display PMFs\n",
    "calculate_and_display_pmfs(data, class_col=\"class\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccee5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
